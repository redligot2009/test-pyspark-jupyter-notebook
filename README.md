## Testing PySpark + Apache Spark with Jupyter Notebook + Conda

Set up virtual environment (Anaconda):
```cmd
conda env create -n hello-spark -f environment.yml
```

Activate virtual environment

```cmd
Activate hello-spark
```

Open Jupyter notebook for dev / testing purposes.
```cmd
jupyter notebook
```